---
- name: Install Clickhouse
  hosts: all
  become: false

  handlers:
  - name: restart kubelet
    service: name=kubelet state=restarted
    become: true


  tasks:
    # - name: Pinger
    #   ansible.builtin.ping:

    - name: Install
      ansible.builtin.apt:
        pkg:
        - apt-transport-https
        - ca-certificates
        - curl
        - gpg
        - pip
        update_cache: true
      become: true

    - name: Mkdir keyrings # Добаление директории 
      ansible.builtin.file:
        path: '/etc/apt/keyrings'
        state: directory
        mode: '0755'
      become: true

    - name: Add gpg key # добавляем ключ
      apt_key:
        url: "https://packages.cloud.google.com/apt/doc/apt-key.gpg"
        state: present
        keyring: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      become: true
  
    - name: Add Example repo # Добавляем репозиторий
      apt_repository:
        repo: 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main'
      become: true

    - name: Install Kubernetes packages. # Установка K8s
      package:
        name: 
          - kubelet
          - kubectl
          - kubeadm
          - kubernetes-cni
          - containerd
        state: present
      notify: restart kubelet
      become: true

    - name: Hold kubeadm # отключим обновления
      ansible.builtin.dpkg_selections:
        name: '{{ item }}'
        selection: hold
      with_items:
        - kubelet 
        - kubeadm
        - kubectl
        - containerd
      become: true

    
    - name: Restart kubelet # презапускаем kubelet
      service:
        name: kubelet
        state: restarted
      become: true

    - name: restart containedr # презапускаем containedr
      service:
        name: containerd
        state: restarted
      become: true

    - name: Remove swapfile from /etc/fstab # В эти двух командах выключаем swap
      mount:
        name: "{{ item }}"
        fstype: swap
        state: absent
      with_items:
        - swap
        - none

    - name: Disable swap
      command: swapoff -a
      when: ansible_swaptotal_mb > 0

    - name: Get br_netfilter # Включаем forwarding// Зарабтала таска
      shell: "{{ item }}"
      #become_user: root
      with_items:
        - modprobe br_netfilter
        - echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf 
        - echo "net.bridge.bridge-nf-call-iptables=1" >> /etc/sysctl.conf
        - echo "net.bridge.bridge-nf-call-arptables=1" >> /etc/sysctl.conf
        - echo "net.bridge.bridge-nf-call-ip6tables=1" >> /etc/sysctl.conf 
        - sysctl -p /etc/sysctl.conf
      become: true

- name: Init K8s
  hosts: Control-node
  become: false   
  tasks:

    # - name: kubernetes.yml --> Install Flannel
    #   shell: kubectl -n kube-system apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
    #   become: yes
    #   environment:
    #     KUBECONFIG: "/etc/kubernetes/admin.conf"
    #   when: inventory_hostname in (groups['masters'] | last)

    - name: Initialize the Kubernetes cluster using kubeadm # инициализируем кластер
      #become_user: root
      shell: "sudo kubeadm init --apiserver-advertise-address={{ ansible_default_ipv4.address}} --pod-network-cidr 10.244.0.0/16 --apiserver-cert-extra-sans={{ ansible_host}}"
      args:
        chdir: $HOME
        creates: cluster_initialized.txt
      become: false
    
    - name: Mkdir HOME/.kube/
      ansible.builtin.file:
        path: '/home/ubuntu/.kube/'
        state: directory
        #group: www-data
        #owner: www-data
        mode: '0755'
      become: false
#-------------------
#Дальше не работает
#------------------

    # - name: Check if Kubernetes has already been initialized.
    #   stat:
    #     path: /etc/kubernetes/admin.conf
    #   register: kubernetes_init_stat

    # # - name: Copy file with owner and permissions
    # #   ansible.builtin.copy:
    # #     src: "/etc/kubernetes/admin.conf"
    # #     dest: "$HOME/.kube/config/"
    # #     remote_src: true
    # #     #become_user: ubuntu
    # #     owner: root
    # #     group: root
    # #     #mode: '0755'
    # #   become: false

    # - name: Mkdir sudo chown HOME/.kube/
    #   ansible.builtin.file:
    #     path: '/home/ubuntu/.kube/config'
    #     recurse: yes
    #     group: ubuntu
    #     owner: ubuntu
    #     mode: '0755'
    #   become: true

    - name: Get permission # даем доступ для обычного пользователя
      shell: "sudo cp -i /etc/kubernetes/admin.conf /home/ubuntu/.kube/config"
      #become_user: ubuntu
      #become: false

    - name: Get permission # даем доступ для обычного пользователя
      shell: "sudo chown ubuntu:ubuntu /home/ubuntu/.kube/config"
      become: false

    # - name: Get permission # даем доступ для обычного пользователя
    #   shell: "{{ item }}"
    #   #become_user: ubuntu
    #   with_items:
    #     #- mkdir -p /home/ubuntu/.kube
    #     - cp -i /etc/kubernetes/admin.conf /home/ubuntu/.kube/config
    #     - sudo chown ubuntu:ubuntu /home/ubuntu/.kube/config
    #   become: false

    - name: Install calico pod network # устанавливаем calico pod network
      become: false
      shell: "{{ item }}"
      with_items:
        - curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml -O
        - kubectl apply -f calico.yaml

    - name: Generate join command # показываем команду с добавлением ноды и записываем ее в переменную
      #become_user: ubuntu
      command: kubeadm token create --print-join-command
      register: join_command

    - name: Copy join command to local file # создаем локальный файл и добавляем туда переменную для присоединения ноды
      local_action: copy content="{{ join_command.stdout_lines[0] }}" dest="./join-command"

- name: Init nodes
  hosts: Work-node
  become: false   
  tasks:
    # tasks file for node_invite
    - name: Copy the join command to server location # копируем файл с нашей комадной для присоединения ноды на сервер, меняем расширение и добавляем права на исполнение
      copy: src=join-command dest=/tmp/join-command.sh mode=0777

    - name: Join the node to cluster # запускаем наш файл
      command: sh /tmp/join-command.sh
      become: true

- name: Deployment app
  hosts: Control-node
  become: false   
  tasks:

  - name: install pre-requisites
    pip:
      name:
        - openshift
        - pyyaml
        - kubernetes 

  - name: Create a k8s namespace
    kubernetes.core.k8s:
      name: app
      api_version: v1
      kind: Namespace
      state: present

  - name: Create a Service object from an inline definition
    kubernetes.core.k8s:
      state: present
      definition:
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: back
          namespace: app
          labels:
            app: back
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: back
          template:
            metadata:
              labels:
                app: back
            spec:
              containers:
              - name: back
                image: wbitt/network-multitool
                env:
                  - name: HTTP_PORT
                    value: "8080"
                ports:
                - containerPort: 8080

    - name: Create a Deployment back from a local file
      kubernetes.core.k8s:
        state: present
        template: './deployment/deployment_back.yaml'

    - name: Create a Deployment cache from a local file
      kubernetes.core.k8s:
        state: present
        template: './deployment/deployment_cache.yaml'

    - name: Create a Deployment front from a local file
      kubernetes.core.k8s:
        state: present
        template: './deployment/deployment_front.yaml'

    - name: Create a service front from a local file
      kubernetes.core.k8s:
        state: present
        template: './service/service_front.yaml'

    - name: Create a service cache from a local file
      kubernetes.core.k8s:
        state: present
        template: './service/service_cache.yaml'

    - name: Create a service back from a local file
      kubernetes.core.k8s:
        state: present
        template: './service/service_back.yaml'

    # - name: Ingress not full pods from a local file
    #   kubernetes.core.k8s:
    #     state: absent
    #     template: './ingress/ingress-all.yaml'

    - name: Ingress not full pods from a local file
      kubernetes.core.k8s:
        state: present
        template: './ingress/ingress-not.yaml'

    - name: Ingress backend -> cache from a local file
      kubernetes.core.k8s:
        state: present
        template: './ingress/ingress-back.yaml'

    - name: Ingress cache from a local file
      kubernetes.core.k8s:
        state: present
        template: './ingress/ingress-cache.yaml'

    - name: Ingress frontend -> backend from a local file
      kubernetes.core.k8s:
        state: present
        template: './ingress/ingress-front.yaml'